model:
  _target_: src.model.TinyDSCNN
  n_classes: ${len:${train_dataloader.dataset.idx_to_keyword}}

train_dataloader:
  _target_: torch.utils.data.DataLoader
  num_workers: 8
  batch_size: 128 # 256
  prefetch_factor: 2
  collate_fn: ${function:src.data.collator}
  shuffle: True
  dataset:
    _target_: src.data.SpotterDataset
    manifest_path: ???
    idx_to_keyword:
    - 'sber'
    - 'joy'
    - 'afina'
    - 'salut'
    - 'filler'
    transforms:
      # waveform-level augmentations
      - _target_: src.data.TAWrapper
        transform:
          _target_: torch_audiomentations.Gain
          min_gain_in_db: -6.0
          max_gain_in_db: 6.0
          p: 0.8
          sample_rate: 16000
          output_type: tensor
      - _target_: src.data.TAWrapper
        transform:
          _target_: torch_audiomentations.AddColoredNoise
          min_snr_in_db: 15.0
          max_snr_in_db: 40.0
          p: 0.5
          sample_rate: 16000
          output_type: tensor
      - _target_: src.data.TAWrapper
        transform:
          _target_: torch_audiomentations.Compose
          p: 0.4
          output_type: tensor
          transforms:
            - _target_: torch_audiomentations.Shift
              min_shift: -0.1
              max_shift: 0.1
              shift_unit: fraction
              rollover: True
              p: 1.0
              sample_rate: 16000
              output_type: tensor
            - _target_: torch_audiomentations.PitchShift
              min_transpose_semitones: -2.0
              max_transpose_semitones: 2.0
              p: 1.0
              sample_rate: 16000
              output_type: tensor
      # spectrogram + log-scale (same 80-mel resolution as teacher)
      - _target_: torchaudio.transforms.MelSpectrogram
        sample_rate: 16000
        n_fft: 512
        win_length: 480
        hop_length: 160
        n_mels: 80
      - _target_: src.data.SpecScaler
      # SpecAugment applied several times for stronger regularisation
      - _target_: torchaudio.transforms.FrequencyMasking
        freq_mask_param: 15
      - _target_: torchaudio.transforms.TimeMasking
        time_mask_param: 20
      - _target_: torchaudio.transforms.FrequencyMasking
        freq_mask_param: 15
      - _target_: torchaudio.transforms.TimeMasking
        time_mask_param: 20
      - _target_: torchaudio.transforms.FrequencyMasking
        freq_mask_param: 10

val_dataloader:
  _target_: torch.utils.data.DataLoader
  num_workers: ${train_dataloader.num_workers}
  batch_size: ${train_dataloader.batch_size}
  prefetch_factor: ${train_dataloader.prefetch_factor}
  collate_fn: ${train_dataloader.collate_fn}
  shuffle: False
  dataset:
    _target_: src.data.SpotterDataset
    manifest_path: ???
    idx_to_keyword: ${train_dataloader.dataset.idx_to_keyword}
    transforms:
      - _target_: torchaudio.transforms.MelSpectrogram
        sample_rate: 16000
        n_fft: 512
        win_length: 480
        hop_length: 160
        n_mels: 80
      - _target_: src.data.SpecScaler

predict_dataloader:
  _target_: torch.utils.data.DataLoader
  num_workers: 1
  batch_size: ${val_dataloader.batch_size}
  prefetch_factor: ${val_dataloader.prefetch_factor}
  collate_fn: ${val_dataloader.collate_fn}
  shuffle: False
  dataset:
    _target_: ${val_dataloader.dataset._target_}
    manifest_path: ???
    idx_to_keyword: ${val_dataloader.dataset.idx_to_keyword}
    transforms: ${val_dataloader.dataset.transforms}
    test: True

trainer:
  _target_: pytorch_lightning.Trainer
  val_check_interval: 0.5
  log_every_n_steps: 10
  precision: bf16-mixed
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0
  accelerator: cuda
  max_steps: 50000 # 30000
  devices: 1
  callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: val/accuracy
      mode: max
      save_top_k: 3
      save_last: True
      filename: "dscnn-step{step}-acc{val/accuracy:.4f}"
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      every_n_train_steps: 5000
      save_top_k: -1
      filename: "dscnn-periodic-step{step}"

logger:
  _target_: pytorch_lightning.loggers.TensorBoardLogger
  save_dir: .

loss:
  _target_: torch.nn.CrossEntropyLoss
  label_smoothing: 0.1

optim:
  _target_: torch.optim.AdamW
  lr: 2e-3
  weight_decay: 0.01
  betas: [0.9, 0.999]

warmup_steps: 2000 # 1000

scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  eta_min: 0.0
